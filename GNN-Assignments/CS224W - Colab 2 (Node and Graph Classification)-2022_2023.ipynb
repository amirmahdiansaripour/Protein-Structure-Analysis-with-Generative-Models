{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"18PQ-B2wDmomjPtHroLNg_aH3hFniLNKn","timestamp":1722938815557},{"file_id":"1gTdOSYXLrSGlqpjKn69lgbIbTK8DhOtY","timestamp":1634599450895},{"file_id":"1Jc5CAEGZIvY0vka3mBdf0tqn2TaJr2O1","timestamp":1610408674518},{"file_id":"1gc6u6hItUKY9uJt6GXHaneSYCMaGcxp1","timestamp":1610395347938},{"file_id":"1CqWY4pk7_VFxi8K8v4asr18ed0Hs8FVA","timestamp":1578441204356}],"collapsed_sections":["67gOQITlCNQi","duLv1BLjJ1FJ","V-loowmHJ8E_","yWvvuK_0KFBQ","Kf4UB2qfW3fa","fsr8OBfJXYbj","r1pO9NVNXezb","A2Z47mvNXovb","VVtYfeENcAJK","VuM0BobAcN8R","8QGX5qTCCGB4"],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"XuXWJLEm2UWS"},"source":["# **CS224W - Colab 2**"]},{"cell_type":"markdown","metadata":{"id":"8gzsP50bF6Gb"},"source":["In Colab 2, we will work to construct our own graph neural network using PyTorch Geometric (PyG) and then apply that model on two Open Graph Benchmark (OGB) datasets. These two datasets will be used to benchmark your model's performance on two different graph-based tasks: 1) node property prediction, predicting properties of single nodes and 2) graph property prediction, predicting properties of entire graphs or subgraphs.\n","\n","First, we will learn how PyTorch Geometric stores graphs as PyTorch tensors.\n","\n","Then, we will load and inspect one of the Open Graph Benchmark (OGB) datasets by using the `ogb` package. OGB is a collection of realistic, large-scale, and diverse benchmark datasets for machine learning on graphs. The `ogb` package not only provides data loaders for each dataset but also model evaluators.\n","\n","Lastly, we will build our own graph neural network using PyTorch Geometric. We will then train and evaluate our model on the OGB node property prediction and graph property prediction tasks.\n","\n","**Note**: Make sure to **sequentially run all the cells in each section**, so that the intermediate variables / packages will carry over to the next cell\n","\n","We recommend you save a copy of this colab in your drive so you don't lose progress!\n","\n","The expected time to finish this Colab is 2 hours. However, debugging training loops can easily take a while. So, don't worry at all if it takes you longer! Have fun and good luck on Colab 2 :)"]},{"cell_type":"markdown","metadata":{"id":"MSaetj53YnT6"},"source":["# Device\n","We recommend using a GPU for this Colab.\n","\n","Please click `Runtime` and then `Change runtime type`. Then set the `hardware accelerator` to **GPU**."]},{"cell_type":"markdown","metadata":{"id":"67gOQITlCNQi"},"source":["## Installation"]},{"cell_type":"code","metadata":{"id":"J_m9l6OYCQZP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1722964359264,"user_tz":-210,"elapsed":2732788,"user":{"displayName":"Amirmahdi Ansaripour","userId":"08650697519467457191"}},"outputId":"a22a6932-8423-4a1a-fa7e-96b8573e00dc"},"source":["# Install torch geometric\n","import os\n","import torch\n","if 'IS_GRADESCOPE_ENV' not in os.environ:\n","  torch_version = str(torch.__version__)\n","  scatter_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n","  sparse_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n","  !pip install torch-scatter -f $scatter_src\n","  !pip install torch-sparse -f $sparse_src\n","  !pip install torch-geometric\n","  !pip install -q git+https://github.com/snap-stanford/deepsnap.git"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in links: https://pytorch-geometric.com/whl/torch-2.3.1+cu121.html\n","Collecting torch-scatter\n","  Downloading torch_scatter-2.1.2.tar.gz (108 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: torch-scatter\n","  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torch-scatter: filename=torch_scatter-2.1.2-cp310-cp310-linux_x86_64.whl size=3594777 sha256=417e576ce6fcae924716ca434a553e5ef3647843564287b848e441a0ca274b77\n","  Stored in directory: /root/.cache/pip/wheels/92/f1/2b/3b46d54b134259f58c8363568569053248040859b1a145b3ce\n","Successfully built torch-scatter\n","Installing collected packages: torch-scatter\n","Successfully installed torch-scatter-2.1.2\n","Looking in links: https://pytorch-geometric.com/whl/torch-2.3.1+cu121.html\n","Collecting torch-sparse\n","  Downloading torch_sparse-0.6.18.tar.gz (209 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.0/210.0 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.13.1)\n","Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.26.4)\n","Building wheels for collected packages: torch-sparse\n","  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torch-sparse: filename=torch_sparse-0.6.18-cp310-cp310-linux_x86_64.whl size=2771735 sha256=a7e069cdbcc0c31ac7b1e7ae03cfe35fb34c81461c9f7f1c70f1c6d91133b081\n","  Stored in directory: /root/.cache/pip/wheels/c9/dd/0f/a6a16f9f3b0236733d257b4b4ea91b548b984a341ed3b8f38c\n","Successfully built torch-sparse\n","Installing collected packages: torch-sparse\n","Successfully installed torch-sparse-0.6.18\n","Collecting torch-geometric\n","  Downloading torch_geometric-2.5.3-py3-none-any.whl.metadata (64 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.13.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.10.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.3.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.3.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.7.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.5.0)\n","Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch-geometric\n","Successfully installed torch-geometric-2.5.3\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for deepsnap (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["!pip install ogb"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5BxP9J17XNky","executionInfo":{"status":"ok","timestamp":1722964806329,"user_tz":-210,"elapsed":3356,"user":{"displayName":"Amirmahdi Ansaripour","userId":"08650697519467457191"}},"outputId":"176d5b57-e4f6-44a8-87f6-edac5df1e99c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ogb\n","  Downloading ogb-1.3.6-py3-none-any.whl.metadata (6.2 kB)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (2.3.1+cu121)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.26.4)\n","Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (4.66.4)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.3.2)\n","Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (2.1.4)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.16.0)\n","Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (2.0.7)\n","Collecting outdated>=0.2.0 (from ogb)\n","  Downloading outdated-0.2.2-py2.py3-none-any.whl.metadata (4.7 kB)\n","Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb) (71.0.4)\n","Collecting littleutils (from outdated>=0.2.0->ogb)\n","  Downloading littleutils-0.2.4-py3-none-any.whl.metadata (679 bytes)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb) (2.31.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb) (2024.1)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb) (2024.1)\n","Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (1.13.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (3.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.15.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (2024.6.1)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (12.1.105)\n","Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (2.3.1)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6.0->ogb) (12.6.20)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->ogb) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (3.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (2024.7.4)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->ogb) (1.3.0)\n","Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n","Downloading littleutils-0.2.4-py3-none-any.whl (8.1 kB)\n","Installing collected packages: littleutils, outdated, ogb\n","Successfully installed littleutils-0.2.4 ogb-1.3.6 outdated-0.2.2\n"]}]},{"cell_type":"code","metadata":{"id":"PRfgbfTjCRD_","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1722964812871,"user_tz":-210,"elapsed":3926,"user":{"displayName":"Amirmahdi Ansaripour","userId":"08650697519467457191"}},"outputId":"bfbccde5-ae1b-464e-d358-9794664f037f"},"source":["import torch_geometric\n","torch_geometric.__version__"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.5.3'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["# 2) Open Graph Benchmark (OGB)\n","\n","The Open Graph Benchmark (OGB) is a collection of realistic, large-scale, and diverse benchmark datasets for machine learning on graphs. Its datasets are automatically downloaded, processed, and split using the OGB Data Loader. The model performance can then be evaluated by using the OGB Evaluator in a unified manner."],"metadata":{"id":"duLv1BLjJ1FJ"}},{"cell_type":"markdown","source":["## Dataset and Data\n","\n","OGB also supports PyG dataset and data classes. Here we take a look on the `ogbn-arxiv` dataset."],"metadata":{"id":"V-loowmHJ8E_"}},{"cell_type":"code","source":["import torch_geometric.transforms as T\n","from ogb.nodeproppred import PygNodePropPredDataset\n","\n","if 'IS_GRADESCOPE_ENV' not in os.environ:\n","  dataset_name = 'ogbn-arxiv'\n","  # Load the dataset and transform it to sparse tensor\n","  dataset = PygNodePropPredDataset(name=dataset_name,\n","                                  transform=T.ToSparseTensor())\n","  print('The {} dataset has {} graph'.format(dataset_name, len(dataset)))\n","\n","  # Extract the graph\n","  data = dataset[0]\n","  print(data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lent3HKcJ1_X","executionInfo":{"status":"ok","timestamp":1722989153558,"user_tz":-210,"elapsed":590,"user":{"displayName":"Amirmahdi Ansaripour","userId":"08650697519467457191"}},"outputId":"054aab44-6249-405e-8ff3-e32a14b7faf2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The ogbn-arxiv dataset has 1 graph\n","Data(num_nodes=169343, x=[169343, 128], node_year=[169343, 1], y=[169343, 1], adj_t=[169343, 169343, nnz=1166243])\n"]}]},{"cell_type":"markdown","source":["## Question 4: How many features are in the ogbn-arxiv graph? (5 points)"],"metadata":{"id":"yWvvuK_0KFBQ"}},{"cell_type":"code","source":["def graph_num_features(data):\n","  # TODO: Implement a function that takes a PyG data object,\n","  # and returns the number of features in the graph (as an integer).\n","\n","  num_features = 0\n","\n","  ############# Your code here ############\n","  num_features = data.x.shape[1] ## [num_of_nodes, num_of_features]\n","\n","  #########################################\n","\n","  return num_features\n","\n","if 'IS_GRADESCOPE_ENV' not in os.environ:\n","  dataset = PygNodePropPredDataset(name=dataset_name,\n","                                  transform=T.ToSparseTensor())\n","  data = dataset[0]\n","  num_features = graph_num_features(data)\n","  print('The graph has {} features'.format(num_features))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-aNYoBA2KFx_","executionInfo":{"status":"ok","timestamp":1722989232521,"user_tz":-210,"elapsed":426,"user":{"displayName":"Amirmahdi Ansaripour","userId":"08650697519467457191"}},"outputId":"df584af7-e5ed-4883-ba25-1dfe39e96f25"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The graph has 128 features\n"]}]},{"cell_type":"markdown","source":["# 3) GNN: Node Property Prediction\n","\n","In this section we will build our first graph neural network using PyTorch Geometric. Then we will apply it to the task of node property prediction (node classification).\n","\n","Specifically, we will use GCN as the foundation for your graph neural network ([Kipf et al. (2017)](https://arxiv.org/pdf/1609.02907.pdf)). To do so, we will work with PyG's built-in `GCNConv` layer."],"metadata":{"id":"Kf4UB2qfW3fa"}},{"cell_type":"markdown","source":["## Setup"],"metadata":{"id":"fsr8OBfJXYbj"}},{"cell_type":"code","source":["os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""],"metadata":{"id":"q36GI1suKPpH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import torch.nn as nn\n","from torch.nn import BatchNorm1d, LogSoftmax"],"metadata":{"id":"hU38U5BLLuHQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn.functional as F\n","print(torch.__version__)\n","\n","# The PyG built-in GCNConv\n","from torch_geometric.nn import GCNConv\n","\n","import torch_geometric.transforms as T\n","from ogb.nodeproppred import PygNodePropPredDataset, Evaluator"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bcHKTAEfXBm7","executionInfo":{"status":"ok","timestamp":1722972998033,"user_tz":-210,"elapsed":4,"user":{"displayName":"Amirmahdi Ansaripour","userId":"08650697519467457191"}},"outputId":"67573f49-6475-4153-e0a0-6eb13198f86c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2.3.1+cu121\n"]}]},{"cell_type":"markdown","source":["## Load and Preprocess the Dataset"],"metadata":{"id":"r1pO9NVNXezb"}},{"cell_type":"code","source":["dataset_name = 'ogbn-arxiv'\n","dataset = PygNodePropPredDataset(name=dataset_name,\n","                                 transform=T.ToSparseTensor())\n","data = dataset[0]\n","\n","# Make the adjacency matrix to symmetric\n","data.adj_t = data.adj_t.to_symmetric()\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# If you use GPU, the device should be cuda\n","print('Device: {}'.format(device))\n","\n","# data = data.to(device)\n","split_idx = dataset.get_idx_split()\n","train_idx = split_idx['train']\n","# train_idx = split_idx['train'].to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vGpqC-1aXcPD","executionInfo":{"status":"ok","timestamp":1722972786531,"user_tz":-210,"elapsed":1122,"user":{"displayName":"Amirmahdi Ansaripour","userId":"08650697519467457191"}},"outputId":"6f5b2060-fbe0-470f-c361-76b3e408ed1c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Device: cuda\n"]}]},{"cell_type":"code","source":["print(data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FcZo6ij7gExT","executionInfo":{"status":"ok","timestamp":1722972795094,"user_tz":-210,"elapsed":505,"user":{"displayName":"Amirmahdi Ansaripour","userId":"08650697519467457191"}},"outputId":"07c86f71-1f33-4859-d2dd-b5cdf4cd6486"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Data(num_nodes=169343, x=[169343, 128], node_year=[169343, 1], y=[169343, 1], adj_t=[169343, 169343, nnz=2315598])\n"]}]},{"cell_type":"code","source":["print(\"Number of nodes in the graph:\\t\\t\", data.num_nodes)\n","print(\"Number of features for each node in the graph:\\t\\t\", data.x.shape[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TY6iMNpseqXE","executionInfo":{"status":"ok","timestamp":1722972790992,"user_tz":-210,"elapsed":588,"user":{"displayName":"Amirmahdi Ansaripour","userId":"08650697519467457191"}},"outputId":"24428d92-09be-43a5-d248-ffc6bf9226e8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of nodes in the graph:\t\t 169343\n","Number of features for each node in the graph:\t\t 128\n"]}]},{"cell_type":"markdown","source":["## GCN Model\n","\n","Now we will implement our GCN model!\n","\n","Please follow the figure below to implement the `forward` function.\n","\n","\n","![test](https://drive.google.com/uc?id=128AuYAXNXGg7PIhJJ7e420DoPWKb-RtL)"],"metadata":{"id":"A2Z47mvNXovb"}},{"cell_type":"code","source":["class GCN(torch.nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim, num_layers,\n","                 dropout_, return_embeds=False):\n","        # TODO: Implement a function that initializes self.convs,\n","        # self.bns, and self.softmax.\n","\n","        super(GCN, self).__init__()\n","\n","        ############# Your code here ############\n","        ## Note:\n","        ## 1. You should use torch.nn.ModuleList for self.convs and self.bns\n","        ## 2. self.convs has num_layers GCNConv layers\n","        ## 3. self.bns has num_layers - 1 BatchNorm1d layers\n","        ## 4. You should use torch.nn.LogSoftmax for self.softmax\n","        ## 5. The parameters you can set for GCNConv include 'in_channels' and\n","        ## 'out_channels'. For more information please refer to the documentation:\n","        ## https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GCNConv\n","        ## 6. The only parameter you need to set for BatchNorm1d is 'num_features'\n","        ## For more information please refer to the documentation:\n","        ## https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html\n","        ## (~10 lines of code)\n","\n","        self.dropout_rate = dropout_\n","        self.return_embeds = return_embeds\n","\n","        self.convs = nn.ModuleList()\n","        self.convs.append(GCNConv(input_dim, hidden_dim))\n","        for i in range(num_layers - 2):\n","          self.convs.append(GCNConv(hidden_dim, hidden_dim))\n","        self.convs.append(GCNConv(hidden_dim, output_dim))\n","        self.bns = nn.ModuleList()\n","        for i in range(num_layers - 1):\n","          self.bns.append(BatchNorm1d(hidden_dim))\n","        self.softmax = LogSoftmax(dim = 1)\n","\n","        #########################################\n","\n","    def reset_parameters(self):\n","        for conv in self.convs:\n","            conv.reset_parameters()\n","        for bn in self.bns:\n","            bn.reset_parameters()\n","\n","    def forward(self, x, adj_t):\n","        ############# Your code here ############\n","        ## Note:\n","        ## 1. Construct the network as shown in the figure\n","        ## 2. torch.nn.functional.relu and torch.nn.functional.dropout are useful\n","        ## For more information please refer to the documentation:\n","        ## https://pytorch.org/docs/stable/nn.functional.html\n","        ## 3. Don't forget to set F.dropout training to self.training\n","        ## 4. If return_embeds is True, then skip the last softmax layer\n","        ## (~7 lines of code)\n","\n","        for i in range(len(self.convs) - 1):\n","           x = self.convs[i](x, adj_t)\n","           x = self.bns[i](x)\n","           x = F.relu(x)\n","           x = F.dropout(x, p = self.dropout_rate, training = self.training)\n","\n","        x = self.convs[-1](x, adj_t) # The last block does not have any BN, relu, Dropout\n","        if self.return_embeds:   # Return embeddings not classes\n","          return x\n","        else:\n","          return self.softmax(x)     # Return classes\n","        #########################################"],"metadata":{"id":"lP-2Cs6jXpnb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(model, data, train_idx, optimizer, loss_fn):\n","    # TODO: Implement a function that trains the model by\n","    # using the given optimizer and loss_fn.\n","    model.train() ## model is in training config\n","    loss = 0\n","\n","    ############# Your code here ############\n","    ## Note:\n","    ## 1. Zero grad the optimizer\n","    ## 2. Feed the data into the model\n","    ## 3. Slice the model output and label by train_idx\n","    ## 4. Feed the sliced output and label to loss_fn\n","    ## (~4 lines of code)\n","\n","    optimizer.zero_grad()\n","\n","    output = model(data.x, data.adj_t)\n","    preds_for_train = output[train_idx]\n","    truth_labels = data.y[train_idx].squeeze()\n","\n","    loss = loss_fn(preds_for_train, labels)\n","\n","\n","    loss.backward()\n","    optimizer.step()\n","    #########################################\n","\n","\n","    return loss.item()"],"metadata":{"id":"kdm-1jQOpQgc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Test function here\n","@torch.no_grad()\n","def test(model, data, split_idx, evaluator, save_model_results=False):\n","    # TODO: Implement a function that tests the model by\n","    # using the given split_idx and evaluator.\n","    model.eval()\n","\n","    # The output of model on all data\n","    out = None\n","\n","    ############# Your code here ############\n","    ## (~1 line of code)\n","    ## Note:\n","    ## 1. No index slicing here\n","    out = model(data.x, data.adj_t)\n","    #########################################\n","\n","    y_pred = out.argmax(dim=-1, keepdim=True)\n","\n","    train_acc = evaluator.eval({\n","        'y_true': data.y[split_idx['train']],\n","        'y_pred': y_pred[split_idx['train']],\n","    })['acc']\n","    valid_acc = evaluator.eval({\n","        'y_true': data.y[split_idx['valid']],\n","        'y_pred': y_pred[split_idx['valid']],\n","    })['acc']\n","    test_acc = evaluator.eval({\n","        'y_true': data.y[split_idx['test']],\n","        'y_pred': y_pred[split_idx['test']],\n","    })['acc']\n","\n","    if save_model_results:\n","      print (\"Saving Model Predictions\")\n","\n","      data = {}\n","      data['y_pred'] = y_pred.view(-1).cpu().detach().numpy()\n","\n","      df = pd.DataFrame(data=data)\n","      # Save locally as csv\n","      df.to_csv('ogbn-arxiv_node.csv', sep=',', index=False)\n","\n","\n","    return train_acc, valid_acc, test_acc"],"metadata":{"id":"7gi0Xq6csRZ8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Please do not change the args\n","if 'IS_GRADESCOPE_ENV' not in os.environ:\n","  args = {\n","      'device': device,\n","      'num_layers': 3,\n","      'hidden_dim': 256,\n","      'dropout': 0.5,\n","      'lr': 0.01,\n","      'epochs': 100,\n","  }\n","  args"],"metadata":{"id":"DWpNs-SrsvHk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Num features: \", data.num_features)\n","print(\"Hidden: \", args['hidden_dim'])\n","print(\"num classes: \", dataset.num_classes)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PPBv2CS73Z71","executionInfo":{"status":"ok","timestamp":1722972909650,"user_tz":-210,"elapsed":428,"user":{"displayName":"Amirmahdi Ansaripour","userId":"08650697519467457191"}},"outputId":"eef01bd9-fe76-4f76-9322-515fc55c8c28"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Num features:  128\n","Hidden:  256\n","num classes:  40\n"]}]},{"cell_type":"code","source":["if 'IS_GRADESCOPE_ENV' not in os.environ:\n","  model = GCN(input_dim = data.num_features,\n","              hidden_dim = args['hidden_dim'],\n","              output_dim = dataset.num_classes,\n","              num_layers = args['num_layers'],\n","              dropout_=args['dropout'])\n","  # model = GCN(input_dim = data.num_features,\n","  #             hidden_dim = args['hidden_dim'],\n","  #             output_dim = dataset.num_classes,\n","  #             num_layers = args['num_layers'],\n","  #             dropout_=args['dropout']).to(device)\n","\n","  evaluator = Evaluator(name='ogbn-arxiv')"],"metadata":{"id":"PfIYD1a3s4ZM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Please do not change these args\n","# Training should take <10min using GPU runtime\n","import copy\n","if 'IS_GRADESCOPE_ENV' not in os.environ:\n","  # reset the parameters to initial random value\n","  model.reset_parameters()\n","\n","  optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n","  loss_fn = F.nll_loss\n","\n","  best_model = None\n","  best_valid_acc = 0\n","\n","  print(\"Train idx: \", train_idx.shape)\n","  print(\"Split train: \", split_idx['train'].shape)\n","  print(\"Split test: \", split_idx['train'].shape)\n","  print(\"Split val: \", split_idx['valid'].shape)\n","\n","\n","  for epoch in range(1, 1 + args[\"epochs\"]):\n","    loss = train(model, data, train_idx, optimizer, loss_fn)\n","    result = test(model, data, split_idx, evaluator)\n","    train_acc, valid_acc, test_acc = result\n","    if valid_acc > best_valid_acc:\n","        best_valid_acc = valid_acc\n","        best_model = copy.deepcopy(model)\n","    print(f'Epoch: {epoch:02d}, '\n","          f'Loss: {loss:.4f}, '\n","          f'Train: {100 * train_acc:.2f}%, '\n","          f'Valid: {100 * valid_acc:.2f}% '\n","          f'Test: {100 * test_acc:.2f}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kM7Ocbp3tK9u","executionInfo":{"status":"ok","timestamp":1722974140287,"user_tz":-210,"elapsed":1115193,"user":{"displayName":"Amirmahdi Ansaripour","userId":"08650697519467457191"}},"outputId":"819a1d58-73f6-48d4-c988-ee8cfa85d446"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train idx:  torch.Size([90941])\n","Split train:  torch.Size([90941])\n","Split test:  torch.Size([90941])\n","Split val:  torch.Size([29799])\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch_sparse/tensor.py:574: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n","  return torch.sparse_csr_tensor(rowptr, col, value, self.sizes())\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 01, Loss: 4.0876, Train: 18.12%, Valid: 25.54% Test: 23.18%\n","Epoch: 02, Loss: 2.3840, Train: 21.53%, Valid: 20.66% Test: 26.15%\n","Epoch: 03, Loss: 2.0094, Train: 38.48%, Valid: 47.07% Test: 48.01%\n","Epoch: 04, Loss: 1.8520, Train: 43.14%, Valid: 44.09% Test: 43.40%\n","Epoch: 05, Loss: 1.6997, Train: 38.59%, Valid: 24.74% Test: 22.79%\n","Epoch: 06, Loss: 1.6251, Train: 38.71%, Valid: 22.98% Test: 19.21%\n","Epoch: 07, Loss: 1.5445, Train: 38.31%, Valid: 23.36% Test: 19.77%\n","Epoch: 08, Loss: 1.4798, Train: 38.52%, Valid: 24.25% Test: 20.98%\n","Epoch: 09, Loss: 1.4359, Train: 39.77%, Valid: 27.93% Test: 26.08%\n","Epoch: 10, Loss: 1.3995, Train: 41.63%, Valid: 30.66% Test: 31.79%\n","Epoch: 11, Loss: 1.3633, Train: 43.07%, Valid: 31.52% Test: 32.70%\n","Epoch: 12, Loss: 1.3287, Train: 44.17%, Valid: 32.32% Test: 33.18%\n","Epoch: 13, Loss: 1.3047, Train: 45.12%, Valid: 32.97% Test: 33.96%\n","Epoch: 14, Loss: 1.2866, Train: 46.38%, Valid: 34.88% Test: 36.09%\n","Epoch: 15, Loss: 1.2622, Train: 48.07%, Valid: 37.52% Test: 39.66%\n","Epoch: 16, Loss: 1.2418, Train: 50.14%, Valid: 40.95% Test: 43.72%\n","Epoch: 17, Loss: 1.2261, Train: 52.58%, Valid: 44.74% Test: 47.82%\n","Epoch: 18, Loss: 1.2130, Train: 55.02%, Valid: 48.33% Test: 51.67%\n","Epoch: 19, Loss: 1.2032, Train: 56.99%, Valid: 51.41% Test: 54.58%\n","Epoch: 20, Loss: 1.1823, Train: 58.02%, Valid: 53.21% Test: 56.20%\n","Epoch: 21, Loss: 1.1761, Train: 58.26%, Valid: 53.61% Test: 56.43%\n","Epoch: 22, Loss: 1.1690, Train: 57.77%, Valid: 52.62% Test: 55.71%\n","Epoch: 23, Loss: 1.1607, Train: 57.56%, Valid: 52.25% Test: 55.35%\n","Epoch: 24, Loss: 1.1467, Train: 58.24%, Valid: 53.73% Test: 56.64%\n","Epoch: 25, Loss: 1.1440, Train: 59.89%, Valid: 56.88% Test: 59.21%\n","Epoch: 26, Loss: 1.1318, Train: 61.88%, Valid: 59.88% Test: 62.02%\n","Epoch: 27, Loss: 1.1204, Train: 63.50%, Valid: 62.33% Test: 64.01%\n","Epoch: 28, Loss: 1.1181, Train: 64.52%, Valid: 63.71% Test: 65.31%\n","Epoch: 29, Loss: 1.1072, Train: 65.45%, Valid: 64.74% Test: 66.17%\n","Epoch: 30, Loss: 1.1016, Train: 66.30%, Valid: 65.97% Test: 66.98%\n","Epoch: 31, Loss: 1.0944, Train: 67.35%, Valid: 67.05% Test: 67.48%\n","Epoch: 32, Loss: 1.0918, Train: 67.83%, Valid: 67.56% Test: 67.63%\n","Epoch: 33, Loss: 1.0843, Train: 68.09%, Valid: 67.81% Test: 67.79%\n","Epoch: 34, Loss: 1.0796, Train: 68.16%, Valid: 67.81% Test: 67.95%\n","Epoch: 35, Loss: 1.0751, Train: 68.15%, Valid: 67.59% Test: 67.99%\n","Epoch: 36, Loss: 1.0692, Train: 68.13%, Valid: 67.50% Test: 67.94%\n","Epoch: 37, Loss: 1.0647, Train: 68.34%, Valid: 67.66% Test: 67.99%\n","Epoch: 38, Loss: 1.0639, Train: 68.69%, Valid: 67.90% Test: 67.99%\n","Epoch: 39, Loss: 1.0580, Train: 69.16%, Valid: 68.20% Test: 67.92%\n","Epoch: 40, Loss: 1.0511, Train: 69.51%, Valid: 68.30% Test: 67.77%\n","Epoch: 41, Loss: 1.0478, Train: 69.74%, Valid: 68.45% Test: 67.78%\n","Epoch: 42, Loss: 1.0417, Train: 70.06%, Valid: 68.96% Test: 68.28%\n","Epoch: 43, Loss: 1.0399, Train: 70.41%, Valid: 69.54% Test: 68.92%\n","Epoch: 44, Loss: 1.0355, Train: 70.65%, Valid: 69.97% Test: 69.36%\n","Epoch: 45, Loss: 1.0353, Train: 70.77%, Valid: 70.13% Test: 69.57%\n","Epoch: 46, Loss: 1.0279, Train: 70.80%, Valid: 70.23% Test: 69.70%\n","Epoch: 47, Loss: 1.0244, Train: 70.86%, Valid: 70.32% Test: 69.82%\n","Epoch: 48, Loss: 1.0236, Train: 71.07%, Valid: 70.35% Test: 69.66%\n","Epoch: 49, Loss: 1.0196, Train: 71.08%, Valid: 70.29% Test: 69.36%\n","Epoch: 50, Loss: 1.0183, Train: 71.23%, Valid: 70.40% Test: 69.42%\n","Epoch: 51, Loss: 1.0154, Train: 71.33%, Valid: 70.57% Test: 69.89%\n","Epoch: 52, Loss: 1.0100, Train: 71.34%, Valid: 70.42% Test: 70.01%\n","Epoch: 53, Loss: 1.0102, Train: 71.39%, Valid: 70.25% Test: 69.75%\n","Epoch: 54, Loss: 1.0077, Train: 71.43%, Valid: 69.97% Test: 69.23%\n","Epoch: 55, Loss: 1.0028, Train: 71.49%, Valid: 69.93% Test: 68.99%\n","Epoch: 56, Loss: 0.9991, Train: 71.59%, Valid: 70.18% Test: 69.09%\n","Epoch: 57, Loss: 0.9961, Train: 71.66%, Valid: 70.49% Test: 69.44%\n","Epoch: 58, Loss: 0.9938, Train: 71.69%, Valid: 70.65% Test: 69.35%\n","Epoch: 59, Loss: 0.9946, Train: 71.80%, Valid: 70.70% Test: 69.36%\n","Epoch: 60, Loss: 0.9896, Train: 71.85%, Valid: 70.72% Test: 69.52%\n","Epoch: 61, Loss: 0.9868, Train: 71.89%, Valid: 70.69% Test: 69.27%\n","Epoch: 62, Loss: 0.9855, Train: 71.95%, Valid: 70.47% Test: 68.88%\n","Epoch: 63, Loss: 0.9806, Train: 72.08%, Valid: 70.61% Test: 69.05%\n","Epoch: 64, Loss: 0.9789, Train: 72.07%, Valid: 70.73% Test: 69.34%\n","Epoch: 65, Loss: 0.9795, Train: 72.07%, Valid: 70.79% Test: 69.34%\n","Epoch: 66, Loss: 0.9749, Train: 72.09%, Valid: 70.57% Test: 68.86%\n","Epoch: 67, Loss: 0.9742, Train: 72.14%, Valid: 70.67% Test: 68.93%\n","Epoch: 68, Loss: 0.9694, Train: 72.31%, Valid: 70.84% Test: 69.41%\n","Epoch: 69, Loss: 0.9694, Train: 72.38%, Valid: 71.32% Test: 70.29%\n","Epoch: 70, Loss: 0.9642, Train: 72.38%, Valid: 71.35% Test: 70.61%\n","Epoch: 71, Loss: 0.9669, Train: 72.42%, Valid: 71.38% Test: 70.38%\n","Epoch: 72, Loss: 0.9626, Train: 72.43%, Valid: 70.99% Test: 69.42%\n","Epoch: 73, Loss: 0.9597, Train: 72.39%, Valid: 70.56% Test: 68.76%\n","Epoch: 74, Loss: 0.9599, Train: 72.54%, Valid: 70.64% Test: 69.03%\n","Epoch: 75, Loss: 0.9597, Train: 72.77%, Valid: 71.39% Test: 70.49%\n","Epoch: 76, Loss: 0.9570, Train: 72.79%, Valid: 71.49% Test: 70.53%\n","Epoch: 77, Loss: 0.9543, Train: 72.89%, Valid: 71.37% Test: 70.19%\n","Epoch: 78, Loss: 0.9547, Train: 72.85%, Valid: 71.21% Test: 70.14%\n","Epoch: 79, Loss: 0.9500, Train: 72.79%, Valid: 71.06% Test: 69.94%\n","Epoch: 80, Loss: 0.9480, Train: 72.84%, Valid: 71.28% Test: 69.90%\n","Epoch: 81, Loss: 0.9478, Train: 72.94%, Valid: 71.19% Test: 69.43%\n","Epoch: 82, Loss: 0.9434, Train: 72.98%, Valid: 71.06% Test: 69.34%\n","Epoch: 83, Loss: 0.9430, Train: 73.14%, Valid: 71.55% Test: 70.71%\n","Epoch: 84, Loss: 0.9434, Train: 73.12%, Valid: 71.55% Test: 70.88%\n","Epoch: 85, Loss: 0.9406, Train: 73.12%, Valid: 71.52% Test: 70.81%\n","Epoch: 86, Loss: 0.9366, Train: 72.97%, Valid: 71.43% Test: 70.53%\n","Epoch: 87, Loss: 0.9328, Train: 72.92%, Valid: 71.43% Test: 70.50%\n","Epoch: 88, Loss: 0.9344, Train: 73.03%, Valid: 71.52% Test: 70.71%\n","Epoch: 90, Loss: 0.9317, Train: 73.19%, Valid: 71.61% Test: 70.41%\n","Epoch: 91, Loss: 0.9287, Train: 73.18%, Valid: 71.57% Test: 70.46%\n","Epoch: 92, Loss: 0.9271, Train: 73.18%, Valid: 71.64% Test: 70.76%\n","Epoch: 93, Loss: 0.9256, Train: 73.24%, Valid: 71.87% Test: 71.16%\n","Epoch: 94, Loss: 0.9242, Train: 73.41%, Valid: 71.82% Test: 71.00%\n","Epoch: 95, Loss: 0.9233, Train: 73.49%, Valid: 71.80% Test: 70.96%\n","Epoch: 96, Loss: 0.9215, Train: 73.38%, Valid: 71.70% Test: 71.02%\n","Epoch: 97, Loss: 0.9192, Train: 73.33%, Valid: 71.56% Test: 70.91%\n","Epoch: 98, Loss: 0.9189, Train: 73.57%, Valid: 71.57% Test: 70.16%\n","Epoch: 99, Loss: 0.9222, Train: 73.69%, Valid: 71.74% Test: 70.32%\n","Epoch: 100, Loss: 0.9182, Train: 73.55%, Valid: 71.90% Test: 71.43%\n"]}]},{"cell_type":"markdown","source":["## Question 5: What are your `best_model` validation and test accuracies?(20 points)\n","\n","Run the cell below to see the results of your best of model and save your model's predictions to a file named *ogbn-arxiv_node.csv*. You can view this file by clicking on the *Folder* icon on the left side pannel. Report the results on Gradescope."],"metadata":{"id":"VVtYfeENcAJK"}},{"cell_type":"code","source":["if 'IS_GRADESCOPE_ENV' not in os.environ:\n","  best_result = test(best_model, data, split_idx, evaluator, save_model_results=True)\n","  train_acc, valid_acc, test_acc = best_result\n","  print(f'Best model: '\n","        f'Train: {100 * train_acc:.2f}%, '\n","        f'Valid: {100 * valid_acc:.2f}% '\n","        f'Test: {100 * test_acc:.2f}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QLhVhmPBcBBS","executionInfo":{"status":"ok","timestamp":1722977112047,"user_tz":-210,"elapsed":4431,"user":{"displayName":"Amirmahdi Ansaripour","userId":"08650697519467457191"}},"outputId":"9e790012-938c-48d7-88a0-ef85873045fb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best model: Train: 73.55%, Valid: 71.90% Test: 71.43%\n"]}]},{"cell_type":"markdown","source":["# 4) GNN: Graph Property Prediction\n","\n","In this section we will create a graph neural network for graph property prediction (graph classification).\n"],"metadata":{"id":"VuM0BobAcN8R"}},{"cell_type":"code","source":["from ogb.graphproppred import PygGraphPropPredDataset, Evaluator\n","from torch_geometric.data import DataLoader\n","from tqdm.notebook import tqdm\n","\n","if 'IS_GRADESCOPE_ENV' not in os.environ:\n","  # Load the dataset\n","  dataset = PygGraphPropPredDataset(name='ogbg-molhiv')\n","\n","  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","  print('Device: {}'.format(device))\n","\n","  split_idx = dataset.get_idx_split()\n","\n","  # Check task type\n","  print('Task type: {}'.format(dataset.task_type))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DSVIWUivcOhh","executionInfo":{"status":"ok","timestamp":1722977214642,"user_tz":-210,"elapsed":8149,"user":{"displayName":"Amirmahdi Ansaripour","userId":"08650697519467457191"}},"outputId":"77ea71e4-d2ac-4ddb-b855-c1d3f74767e3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://snap.stanford.edu/ogb/data/graphproppred/csv_mol_download/hiv.zip\n"]},{"output_type":"stream","name":"stderr","text":["Downloaded 0.00 GB: 100%|██████████| 3/3 [00:02<00:00,  1.24it/s]\n","Processing...\n"]},{"output_type":"stream","name":"stdout","text":["Extracting dataset/hiv.zip\n","Loading necessary files...\n","This might take a while.\n","Processing graphs...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 41127/41127 [00:00<00:00, 77431.90it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Converting graphs into PyG objects...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 41127/41127 [00:01<00:00, 22985.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Saving...\n","Device: cuda\n","Task type: binary classification\n"]},{"output_type":"stream","name":"stderr","text":["Done!\n"]}]},{"cell_type":"code","source":["# Load the dataset splits into corresponding dataloaders\n","# We will train the graph classification task on a batch of 32 graphs\n","# Shuffle the order of graphs for training set\n","if 'IS_GRADESCOPE_ENV' not in os.environ:\n","  train_loader = DataLoader(dataset[split_idx[\"train\"]], batch_size=32, shuffle=True, num_workers=0)\n","  valid_loader = DataLoader(dataset[split_idx[\"valid\"]], batch_size=32, shuffle=False, num_workers=0)\n","  test_loader = DataLoader(dataset[split_idx[\"test\"]], batch_size=32, shuffle=False, num_workers=0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e5pgebY_cjGC","executionInfo":{"status":"ok","timestamp":1722977237605,"user_tz":-210,"elapsed":575,"user":{"displayName":"Amirmahdi Ansaripour","userId":"08650697519467457191"}},"outputId":"27adfada-d8df-45bb-9e5c-be29afffe7c7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n","  warnings.warn(out)\n"]}]},{"cell_type":"code","source":["if 'IS_GRADESCOPE_ENV' not in os.environ:\n","  # Please do not change the args\n","  args = {\n","      'device': device,\n","      'num_layers': 5,\n","      'hidden_dim': 256,\n","      'dropout': 0.5,\n","      'lr': 0.001,\n","      'epochs': 30,\n","  }\n","  args"],"metadata":{"id":"ekCCv4qxcmA6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Graph Mini-Batching\n","Before diving into the actual model, we introduce the concept of mini-batching with graphs. In order to parallelize the processing of a mini-batch of graphs, PyG combines the graphs into a single disconnected graph data object (*torch_geometric.data.Batch*). *torch_geometric.data.Batch* inherits from *torch_geometric.data.Data* (introduced earlier) and contains an additional attribute called `batch`.\n","\n","The `batch` attribute is a vector mapping each node to the index of its corresponding graph within the mini-batch:\n","\n","    batch = [0, ..., 0, 1, ..., n - 2, n - 1, ..., n - 1]\n","\n","This attribute is crucial for associating which graph each node belongs to and can be used to e.g. average the node embeddings for each graph individually to compute graph level embeddings."],"metadata":{"id":"A_eQzDZXn4YP"}},{"cell_type":"markdown","source":["### Implemention\n","Now, we have all of the tools to implement a GCN Graph Prediction model!  \n","\n","We will reuse the existing GCN model to generate `node_embeddings` and then use  `Global Pooling` over the nodes to create graph level embeddings that can be used to predict properties for the each graph. Remeber that the `batch` attribute will be essential for performining Global Pooling over our mini-batch of graphs."],"metadata":{"id":"Im58Crf6pnM2"}},{"cell_type":"code","source":["from ogb.graphproppred.mol_encoder import AtomEncoder\n","from torch_geometric.nn import global_add_pool, global_mean_pool\n","\n","### GCN to predict graph property\n","class GCN_Graph(torch.nn.Module):\n","    def __init__(self, hidden_dim, output_dim, num_layers, dropout):\n","        super(GCN_Graph, self).__init__()\n","\n","        # Load encoders for Atoms in molecule graphs\n","        self.node_encoder = AtomEncoder(hidden_dim)\n","        print(\"Node encoder: \", self.node_encoder)\n","\n","        # Node embedding model\n","        # Note that the input_dim and output_dim are set to hidden_dim\n","        self.gnn_node = GCN(input_dim=hidden_dim, hidden_dim=hidden_dim,\n","                            output_dim=hidden_dim, num_layers = num_layers,\n","                            dropout_ = dropout, return_embeds=True) # It returns embeddings not softmax (node prediction part)\n","\n","        self.pool = None\n","\n","        ############# Your code here ############\n","        ## Note:\n","        ## 1. Initialize self.pool as a global mean pooling layer\n","        ## For more information please refer to the documentation:\n","        ## https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#global-pooling-layers\n","        self.pool = global_mean_pool\n","\n","        #########################################\n","\n","        # Output layer\n","        self.linear = torch.nn.Linear(hidden_dim, output_dim)\n","\n","\n","    def reset_parameters(self):\n","      self.gnn_node.reset_parameters()\n","      self.linear.reset_parameters()\n","\n","    def forward(self, batched_data):\n","        # TODO: Implement a function that takes as input a\n","        # mini-batch of graphs (torch_geometric.data.Batch) and\n","        # returns the predicted graph property for each graph.\n","        #\n","        # NOTE: Since we are predicting graph level properties,\n","        # your output will be a tensor with dimension equaling\n","        # the number of graphs in the mini-batch\n","\n","\n","        # Extract important attributes of our mini-batch\n","        # print(\"Batched data type: \", type(batched_data))\n","        # Batched data type:  <class 'torch_geometric.data.batch.DataBatch'>\n","        # print(\"Batched data: \", batched_data)\n","        # Batched data:  DataBatch(edge_index=[2, 1572], edge_attr=[1572, 3], x=[744, 9], y=[32, 1], num_nodes=744, batch=[744], ptr=[33])\n","        x, edge_index, batch = batched_data.x, batched_data.edge_index, batched_data.batch\n","        embed = self.node_encoder(x)\n","\n","        out = None\n","\n","        ############# Your code here ############\n","        ## Note:\n","        ## 1. Construct node embeddings using existing GCN model\n","        ## 2. Use the global pooling layer to aggregate features for each individual graph\n","        ## For more information please refer to the documentation:\n","        ## https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#global-pooling-layers\n","        ## 3. Use a linear layer to predict each graph's property\n","        ## (~3 lines of code)\n","        node_embeddings = self.gnn_node(embed, edge_index) # Just like model(x, adj_t) in the previous GCN part\n","        # print(\"Node embedding shape: \", node_embeddings.shape)\n","        # Node embedding shape:  torch.Size([744, 256])\n","        graph_embedding = self.pool(node_embeddings, batch)\n","        # print(\"Graph embedding shape: \", graph_embedding.shape)\n","        # Graph embedding shape:  torch.Size([32, 256])\n","        out = self.linear(graph_embedding)\n","        # print(\"Out shape: \", out.shape)\n","        # Out shape:  torch.Size([32, 1])\n","        #########################################\n","\n","        return out"],"metadata":{"id":"a5xbrHggcqTb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(model, device, data_loader, optimizer, loss_fn):\n","    # TODO: Implement a function that trains your model by\n","    # using the given optimizer and loss_fn.\n","    model.train()\n","    loss = 0\n","\n","    for step, batch in enumerate(data_loader):\n","      batch = batch.to(device)\n","\n","      if batch.x.shape[0] == 1 or batch.batch[-1] == 0:\n","          pass\n","      else:\n","        ## ignore nan targets (unlabeled) when computing training loss.\n","        is_labeled = batch.y == batch.y\n","\n","        ############# Your code here ############\n","        ## Note:\n","        ## 1. Zero grad the optimizer\n","        ## 2. Feed the data into the model\n","        ## 3. Use `is_labeled` mask to filter output and labels\n","        ## 4. You may need to change the type of label to torch.float32\n","        ## 5. Feed the output and label to the loss_fn\n","        ## (~3 lines of code)\n","        optimizer.zero_grad()\n","        output = model(batch)\n","        labels = batch.y[is_labeled].type(torch.float32)\n","        output = output[is_labeled]\n","        loss = loss_fn(input = output, target = labels)\n","        #########################################\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","    return loss.item()"],"metadata":{"id":"DjJDb4pK5D-V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# The evaluation function\n","def eval(model, device, loader, evaluator, save_model_results=False, save_file=None):\n","    model.eval()\n","    y_true = []\n","    y_pred = []\n","\n","    for step, batch in enumerate(loader):\n","        batch = batch.to(device)\n","\n","        if batch.x.shape[0] == 1:\n","            pass\n","        else:\n","            with torch.no_grad():\n","                pred = model(batch)\n","\n","            y_true.append(batch.y.view(pred.shape).detach().cpu())\n","            y_pred.append(pred.detach().cpu())\n","\n","    y_true = torch.cat(y_true, dim = 0).numpy()\n","    y_pred = torch.cat(y_pred, dim = 0).numpy()\n","\n","    input_dict = {\"y_true\": y_true, \"y_pred\": y_pred}\n","\n","    if save_model_results:\n","        print (\"Saving Model Predictions\")\n","\n","        # Create a pandas dataframe with a two columns\n","        # y_pred | y_true\n","        data = {}\n","        data['y_pred'] = y_pred.reshape(-1)\n","        data['y_true'] = y_true.reshape(-1)\n","\n","        df = pd.DataFrame(data=data)\n","        # Save to csv\n","        df.to_csv('ogbg-molhiv_graph_' + save_file + '.csv', sep=',', index=False)\n","\n","    return evaluator.eval(input_dict)"],"metadata":{"id":"-vDgrGFI5w71"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if 'IS_GRADESCOPE_ENV' not in os.environ:\n","  model = GCN_Graph(args['hidden_dim'],\n","              dataset.num_tasks, args['num_layers'],\n","              args['dropout']).to(device)\n","  evaluator = Evaluator(name='ogbg-molhiv')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RiafSTSo6QGX","executionInfo":{"status":"ok","timestamp":1722986316608,"user_tz":-210,"elapsed":575,"user":{"displayName":"Amirmahdi Ansaripour","userId":"08650697519467457191"}},"outputId":"1b65e820-062f-454b-a58e-00caa7170e9b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Node encoder:  AtomEncoder(\n","  (atom_embedding_list): ModuleList(\n","    (0): Embedding(119, 256)\n","    (1): Embedding(5, 256)\n","    (2-3): 2 x Embedding(12, 256)\n","    (4): Embedding(10, 256)\n","    (5-6): 2 x Embedding(6, 256)\n","    (7-8): 2 x Embedding(2, 256)\n","  )\n",")\n"]}]},{"cell_type":"code","source":["# Please do not change these args\n","# Training should take <10min using GPU runtime\n","import copy\n","\n","if 'IS_GRADESCOPE_ENV' not in os.environ:\n","  model.reset_parameters()\n","\n","  optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n","  loss_fn = torch.nn.BCEWithLogitsLoss()\n","\n","  best_model = None\n","  best_valid_acc = 0\n","\n","  for epoch in range(1, 1 + args[\"epochs\"]):\n","    # print('Training...')\n","    loss = train(model, device, train_loader, optimizer, loss_fn)\n","\n","    # print('Evaluating...')\n","    train_result = eval(model, device, train_loader, evaluator)\n","    val_result = eval(model, device, valid_loader, evaluator)\n","    test_result = eval(model, device, test_loader, evaluator)\n","\n","    train_acc, valid_acc, test_acc = train_result[dataset.eval_metric], val_result[dataset.eval_metric], test_result[dataset.eval_metric]\n","    if valid_acc > best_valid_acc:\n","        best_valid_acc = valid_acc\n","        best_model = copy.deepcopy(model)\n","    print(f'Epoch: {epoch:02d}, '\n","          f'Loss: {loss:.4f}, '\n","          f'Train: {100 * train_acc:.2f}%, '\n","          f'Valid: {100 * valid_acc:.2f}% '\n","          f'Test: {100 * test_acc:.2f}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2-cvTxsV6dDX","executionInfo":{"status":"ok","timestamp":1722986971136,"user_tz":-210,"elapsed":652495,"user":{"displayName":"Amirmahdi Ansaripour","userId":"08650697519467457191"}},"outputId":"8d0d1843-8327-4f44-9dda-a52dac2e7ff6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 01, Loss: 0.0561, Train: 72.74%, Valid: 73.11% Test: 70.68%\n","Epoch: 02, Loss: 0.0373, Train: 75.08%, Valid: 74.11% Test: 72.23%\n","Epoch: 03, Loss: 0.0225, Train: 75.70%, Valid: 69.14% Test: 68.75%\n","Epoch: 04, Loss: 0.4226, Train: 76.06%, Valid: 74.48% Test: 73.28%\n","Epoch: 05, Loss: 0.0541, Train: 75.57%, Valid: 73.24% Test: 72.00%\n","Epoch: 06, Loss: 0.0296, Train: 77.64%, Valid: 76.40% Test: 69.34%\n","Epoch: 07, Loss: 0.0279, Train: 79.13%, Valid: 72.81% Test: 69.83%\n","Epoch: 08, Loss: 0.0622, Train: 78.27%, Valid: 73.95% Test: 72.96%\n","Epoch: 09, Loss: 0.0179, Train: 78.69%, Valid: 76.75% Test: 73.78%\n","Epoch: 10, Loss: 0.7289, Train: 80.34%, Valid: 74.73% Test: 70.70%\n","Epoch: 11, Loss: 0.0398, Train: 79.50%, Valid: 76.46% Test: 70.88%\n","Epoch: 12, Loss: 0.1703, Train: 78.90%, Valid: 77.48% Test: 73.62%\n","Epoch: 13, Loss: 0.6975, Train: 80.62%, Valid: 75.57% Test: 73.86%\n","Epoch: 14, Loss: 0.0231, Train: 80.36%, Valid: 77.77% Test: 72.49%\n","Epoch: 15, Loss: 0.0468, Train: 80.91%, Valid: 77.91% Test: 73.65%\n","Epoch: 16, Loss: 0.0309, Train: 81.33%, Valid: 79.02% Test: 74.86%\n","Epoch: 17, Loss: 0.9885, Train: 81.17%, Valid: 75.71% Test: 75.38%\n","Epoch: 18, Loss: 0.0246, Train: 82.32%, Valid: 75.58% Test: 74.52%\n","Epoch: 19, Loss: 0.0320, Train: 81.66%, Valid: 78.14% Test: 74.63%\n","Epoch: 20, Loss: 0.7227, Train: 81.99%, Valid: 77.51% Test: 74.95%\n","Epoch: 21, Loss: 0.0546, Train: 82.67%, Valid: 76.83% Test: 73.08%\n","Epoch: 22, Loss: 0.0170, Train: 82.56%, Valid: 75.73% Test: 74.13%\n","Epoch: 23, Loss: 0.0236, Train: 83.07%, Valid: 76.42% Test: 73.88%\n","Epoch: 24, Loss: 0.8686, Train: 83.47%, Valid: 77.89% Test: 75.50%\n","Epoch: 25, Loss: 0.0340, Train: 83.67%, Valid: 79.21% Test: 76.64%\n","Epoch: 26, Loss: 0.0334, Train: 83.21%, Valid: 76.93% Test: 75.01%\n","Epoch: 27, Loss: 0.0145, Train: 83.85%, Valid: 78.74% Test: 75.67%\n","Epoch: 28, Loss: 0.0190, Train: 83.80%, Valid: 79.32% Test: 75.71%\n","Epoch: 29, Loss: 0.2837, Train: 83.95%, Valid: 78.72% Test: 76.28%\n","Epoch: 30, Loss: 0.0184, Train: 83.95%, Valid: 77.26% Test: 77.78%\n"]}]},{"cell_type":"markdown","source":["## Question 6: What are your `best_model` validation and test ROC-AUC scores? (20 points)\n","\n","Run the cell below to see the results of your best of model and save your model's predictions in files named *ogbg-molhiv_graph_[valid,test].csv*. Again, you can view the files by clicking on the *Folder* icon on the left side pannel. Report the results on Gradescope."],"metadata":{"id":"8QGX5qTCCGB4"}},{"cell_type":"code","source":["if 'IS_GRADESCOPE_ENV' not in os.environ:\n","  train_auroc = eval(best_model, device, train_loader, evaluator)[dataset.eval_metric]\n","  valid_auroc = eval(best_model, device, valid_loader, evaluator)[dataset.eval_metric]\n","  test_auroc  = eval(best_model, device, test_loader, evaluator)[dataset.eval_metric]\n","\n","  print(f'Best model: '\n","      f'Train: {100 * train_auroc:.2f}%, '\n","      f'Valid: {100 * valid_auroc:.2f}% '\n","      f'Test: {100 * test_auroc:.2f}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GtT_IEwVB9nO","executionInfo":{"status":"ok","timestamp":1722987110464,"user_tz":-210,"elapsed":9358,"user":{"displayName":"Amirmahdi Ansaripour","userId":"08650697519467457191"}},"outputId":"069aebc5-55cf-4f5f-ac06-e0a7802a30e2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best model: Train: 83.80%, Valid: 79.32% Test: 75.71%\n"]}]}]}